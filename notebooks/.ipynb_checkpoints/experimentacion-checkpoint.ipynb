{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gmt time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67373</th>\n",
       "      <td>10.02.2014 07:00:00.000</td>\n",
       "      <td>102.389</td>\n",
       "      <td>102.428</td>\n",
       "      <td>102.105</td>\n",
       "      <td>102.195</td>\n",
       "      <td>6408.7598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91232</th>\n",
       "      <td>06.12.2017 13:00:00.000</td>\n",
       "      <td>112.172</td>\n",
       "      <td>112.221</td>\n",
       "      <td>112.040</td>\n",
       "      <td>112.197</td>\n",
       "      <td>10456.4199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68141</th>\n",
       "      <td>26.03.2014 06:00:00.000</td>\n",
       "      <td>102.296</td>\n",
       "      <td>102.325</td>\n",
       "      <td>102.280</td>\n",
       "      <td>102.324</td>\n",
       "      <td>1795.2800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10449</th>\n",
       "      <td>03.01.2005 22:00:00.000</td>\n",
       "      <td>102.784</td>\n",
       "      <td>102.853</td>\n",
       "      <td>102.753</td>\n",
       "      <td>102.827</td>\n",
       "      <td>12838.2998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105625</th>\n",
       "      <td>01.04.2020 01:00:00.000</td>\n",
       "      <td>107.496</td>\n",
       "      <td>107.741</td>\n",
       "      <td>107.433</td>\n",
       "      <td>107.717</td>\n",
       "      <td>14351.2197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Gmt time     Open     High      Low    Close  \\\n",
       "67373   10.02.2014 07:00:00.000  102.389  102.428  102.105  102.195   \n",
       "91232   06.12.2017 13:00:00.000  112.172  112.221  112.040  112.197   \n",
       "68141   26.03.2014 06:00:00.000  102.296  102.325  102.280  102.324   \n",
       "10449   03.01.2005 22:00:00.000  102.784  102.853  102.753  102.827   \n",
       "105625  01.04.2020 01:00:00.000  107.496  107.741  107.433  107.717   \n",
       "\n",
       "            Volume  \n",
       "67373    6408.7598  \n",
       "91232   10456.4199  \n",
       "68141    1795.2800  \n",
       "10449   12838.2998  \n",
       "105625  14351.2197  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import talib\n",
    "from utils import utils\n",
    "\n",
    "df = pd.read_csv('../data/USDJPY.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_all_indicators?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.rename_columns_and_format(df)\n",
    "df = utils.get_all_indicators(df)\n",
    "\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ventana bidimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(x_input, y_input):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    #kernel = 2,1 o 1,2 y maxpooling tmb\n",
    "    #tamano kernel mas grande (dias)\n",
    "    model.add(tf.keras.layers.Conv2D(32, (2, 2), input_shape=(x_input, y_input,1), activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(1, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 2 from 1 for 'conv2d/Conv2D' (op: 'Conv2D') with input shapes: [?,1,15,1], [2,2,1,32].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1618\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1619\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1620\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'conv2d/Conv2D' (op: 'Conv2D') with input shapes: [?,1,15,1], [2,2,1,32].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f3f71835616a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     history = model.fit(np.expand_dims(x_train, axis=3), \n",
      "\u001b[0;32m<ipython-input-3-919b294a47e3>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(x_input, y_input)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    183\u001b[0m           \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m           \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    772\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m   1133\u001b[0m           call_from_convolution=False)\n\u001b[1;32m   1134\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;31m# copybara:strip_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0;31m# copybara:insert return self.conv_op(inp, filter)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         name=self.name)\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\u001b[0m\n\u001b[1;32m   2009\u001b[0m                            \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m                            \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m                            name=name)\n\u001b[0m\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    967\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                   \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m                   data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[1;32m    970\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    740\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    741\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3320\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3321\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3322\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3323\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3324\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1784\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1785\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1786\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1787\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1620\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1621\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1622\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'conv2d/Conv2D' (op: 'Conv2D') with input shapes: [?,1,15,1], [2,2,1,32]."
     ]
    }
   ],
   "source": [
    "window = 15\n",
    "p_train = 0.8\n",
    "\n",
    "df = df.head(500)\n",
    "\n",
    "columns = ['close', 'ema_12', 'ema_26', 'upper_bband', \n",
    "         'middle_bband', 'lower_bband', 'rsi', \n",
    "         'macd', 'macd_signal', 'macd_hist', 'k', 'd']\n",
    "\n",
    "target_column = df['close'].to_numpy()\n",
    "\n",
    "for column in columns:\n",
    "    df_min = df[column]\n",
    "    x, y = utils.create_windowed_dataset(df_min, target_column, window)\n",
    "    x_train, x_test, y_train, y_test = utils.train_test_split(p_train, x, y)\n",
    "    \n",
    "    _, x_input, y_input = x.shape\n",
    "    model = get_model(x_input, y_input)\n",
    "    \n",
    "    history = model.fit(np.expand_dims(x_train, axis=3), \n",
    "                    y_train, \n",
    "                    validation_data=(np.expand_dims(x_test, axis=3),y_test), \n",
    "                    batch_size=32, \n",
    "                    epochs=5)\n",
    "    \n",
    "    df_history = pd.DataFrame(history.history)\n",
    "    df_history.to_csv(f'./metrics{column}_performance.csv')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 388 samples, validate on 97 samples\n",
      "Epoch 1/100\n",
      "388/388 [==============================] - 3s 7ms/sample - loss: 14534.2099 - root_mean_squared_error: 120.5579 - val_loss: 14267.8615 - val_root_mean_squared_error: 119.4482\n",
      "Epoch 2/100\n",
      "388/388 [==============================] - 0s 278us/sample - loss: 13833.9211 - root_mean_squared_error: 117.6177 - val_loss: 14017.5237 - val_root_mean_squared_error: 118.3956\n",
      "Epoch 3/100\n",
      "388/388 [==============================] - 0s 269us/sample - loss: 13731.5828 - root_mean_squared_error: 117.1818 - val_loss: 14014.4732 - val_root_mean_squared_error: 118.3827\n",
      "Epoch 4/100\n",
      "388/388 [==============================] - 0s 277us/sample - loss: 13690.0112 - root_mean_squared_error: 117.0043 - val_loss: 14011.4224 - val_root_mean_squared_error: 118.3699\n",
      "Epoch 5/100\n",
      "388/388 [==============================] - 0s 243us/sample - loss: 13670.7189 - root_mean_squared_error: 116.9219 - val_loss: 14008.3681 - val_root_mean_squared_error: 118.3569\n",
      "Epoch 6/100\n",
      "388/388 [==============================] - 0s 263us/sample - loss: 13662.4874 - root_mean_squared_error: 116.8867 - val_loss: 14005.3127 - val_root_mean_squared_error: 118.3440\n",
      "Epoch 7/100\n",
      "388/388 [==============================] - 0s 269us/sample - loss: 13654.4154 - root_mean_squared_error: 116.8521 - val_loss: 14002.2537 - val_root_mean_squared_error: 118.3311\n",
      "Epoch 8/100\n",
      "388/388 [==============================] - 0s 296us/sample - loss: 13653.0832 - root_mean_squared_error: 116.8464 - val_loss: 13999.1961 - val_root_mean_squared_error: 118.3182\n",
      "Epoch 9/100\n",
      "388/388 [==============================] - 0s 297us/sample - loss: 13646.4555 - root_mean_squared_error: 116.8180 - val_loss: 13996.1339 - val_root_mean_squared_error: 118.3053\n",
      "Epoch 10/100\n",
      "388/388 [==============================] - 0s 312us/sample - loss: 13643.8370 - root_mean_squared_error: 116.8068 - val_loss: 13993.0720 - val_root_mean_squared_error: 118.2923\n",
      "Epoch 11/100\n",
      "388/388 [==============================] - 0s 282us/sample - loss: 13639.4747 - root_mean_squared_error: 116.7882 - val_loss: 13990.0092 - val_root_mean_squared_error: 118.2794\n",
      "Epoch 12/100\n",
      "388/388 [==============================] - 0s 315us/sample - loss: 13634.1834 - root_mean_squared_error: 116.7655 - val_loss: 13986.9467 - val_root_mean_squared_error: 118.2664\n",
      "Epoch 13/100\n",
      "388/388 [==============================] - 0s 305us/sample - loss: 13630.1150 - root_mean_squared_error: 116.7481 - val_loss: 13983.8828 - val_root_mean_squared_error: 118.2535\n",
      "Epoch 14/100\n",
      "388/388 [==============================] - 0s 348us/sample - loss: 13626.4832 - root_mean_squared_error: 116.7325 - val_loss: 13980.8210 - val_root_mean_squared_error: 118.2405\n",
      "Epoch 15/100\n",
      "388/388 [==============================] - 0s 383us/sample - loss: 13623.3071 - root_mean_squared_error: 116.7189 - val_loss: 13977.7578 - val_root_mean_squared_error: 118.2276\n",
      "Epoch 16/100\n",
      "388/388 [==============================] - 0s 347us/sample - loss: 13620.1229 - root_mean_squared_error: 116.7053 - val_loss: 13974.2773 - val_root_mean_squared_error: 118.2129\n",
      "Epoch 17/100\n",
      "388/388 [==============================] - 0s 353us/sample - loss: 13616.8580 - root_mean_squared_error: 116.6913 - val_loss: 13970.8863 - val_root_mean_squared_error: 118.1985\n",
      "Epoch 18/100\n",
      "388/388 [==============================] - 0s 369us/sample - loss: 13613.4614 - root_mean_squared_error: 116.6767 - val_loss: 13967.4101 - val_root_mean_squared_error: 118.1838\n",
      "Epoch 19/100\n",
      "388/388 [==============================] - 0s 363us/sample - loss: 13609.9856 - root_mean_squared_error: 116.6618 - val_loss: 13963.7721 - val_root_mean_squared_error: 118.1684\n",
      "Epoch 20/100\n",
      "388/388 [==============================] - ETA: 0s - loss: 13605.6670 - root_mean_squared_error: 116.643 - 0s 325us/sample - loss: 13606.4355 - root_mean_squared_error: 116.6466 - val_loss: 13960.0189 - val_root_mean_squared_error: 118.1525\n",
      "Epoch 21/100\n",
      "388/388 [==============================] - 0s 307us/sample - loss: 13602.5836 - root_mean_squared_error: 116.6301 - val_loss: 13955.8089 - val_root_mean_squared_error: 118.1347\n",
      "Epoch 22/100\n",
      "388/388 [==============================] - 0s 277us/sample - loss: 13598.4059 - root_mean_squared_error: 116.6122 - val_loss: 13951.0928 - val_root_mean_squared_error: 118.1147\n",
      "Epoch 23/100\n",
      "388/388 [==============================] - 0s 306us/sample - loss: 13592.9826 - root_mean_squared_error: 116.5890 - val_loss: 13943.2122 - val_root_mean_squared_error: 118.0814\n",
      "Epoch 24/100\n",
      "388/388 [==============================] - 0s 342us/sample - loss: 13584.8840 - root_mean_squared_error: 116.5542 - val_loss: 13925.2169 - val_root_mean_squared_error: 118.0052\n",
      "Epoch 25/100\n",
      "388/388 [==============================] - 0s 316us/sample - loss: 13559.9559 - root_mean_squared_error: 116.4472 - val_loss: 13846.7433 - val_root_mean_squared_error: 117.6722\n",
      "Epoch 26/100\n",
      "388/388 [==============================] - 0s 343us/sample - loss: 13392.2788 - root_mean_squared_error: 115.7250 - val_loss: 13396.9246 - val_root_mean_squared_error: 115.7451\n",
      "Epoch 27/100\n",
      "388/388 [==============================] - 0s 378us/sample - loss: 12266.4143 - root_mean_squared_error: 110.7538 - val_loss: 10229.1573 - val_root_mean_squared_error: 101.1393\n",
      "Epoch 28/100\n",
      "388/388 [==============================] - 0s 348us/sample - loss: 7173.3453 - root_mean_squared_error: 84.6956 - val_loss: 835.9268 - val_root_mean_squared_error: 28.9124\n",
      "Epoch 29/100\n",
      "388/388 [==============================] - 0s 338us/sample - loss: 5087.6854 - root_mean_squared_error: 71.3280 - val_loss: 1980.2724 - val_root_mean_squared_error: 44.5003\n",
      "Epoch 30/100\n",
      "388/388 [==============================] - 0s 318us/sample - loss: 4766.9076 - root_mean_squared_error: 69.0428 - val_loss: 1889.2669 - val_root_mean_squared_error: 43.4657\n",
      "Epoch 31/100\n",
      "388/388 [==============================] - 0s 322us/sample - loss: 4501.8454 - root_mean_squared_error: 67.0958 - val_loss: 1275.2459 - val_root_mean_squared_error: 35.7106\n",
      "Epoch 32/100\n",
      "388/388 [==============================] - 0s 355us/sample - loss: 4366.0812 - root_mean_squared_error: 66.0763 - val_loss: 2047.3772 - val_root_mean_squared_error: 45.2480\n",
      "Epoch 33/100\n",
      "388/388 [==============================] - 0s 317us/sample - loss: 4068.9679 - root_mean_squared_error: 63.7885 - val_loss: 1331.3330 - val_root_mean_squared_error: 36.4874\n",
      "Epoch 34/100\n",
      "388/388 [==============================] - 0s 267us/sample - loss: 4408.9142 - root_mean_squared_error: 66.3997 - val_loss: 2076.9577 - val_root_mean_squared_error: 45.5737\n",
      "Epoch 35/100\n",
      "388/388 [==============================] - 0s 275us/sample - loss: 3553.0555 - root_mean_squared_error: 59.6075 - val_loss: 1474.6864 - val_root_mean_squared_error: 38.4016\n",
      "Epoch 36/100\n",
      "388/388 [==============================] - 0s 319us/sample - loss: 3974.3557 - root_mean_squared_error: 63.0425 - val_loss: 1555.2843 - val_root_mean_squared_error: 39.4371\n",
      "Epoch 37/100\n",
      "388/388 [==============================] - 0s 314us/sample - loss: 3950.4107 - root_mean_squared_error: 62.8523 - val_loss: 1704.5611 - val_root_mean_squared_error: 41.2863\n",
      "Epoch 38/100\n",
      "388/388 [==============================] - 0s 302us/sample - loss: 3633.3997 - root_mean_squared_error: 60.2777 - val_loss: 1812.3002 - val_root_mean_squared_error: 42.5711\n",
      "Epoch 39/100\n",
      "388/388 [==============================] - 0s 289us/sample - loss: 3254.2658 - root_mean_squared_error: 57.0462 - val_loss: 1850.6105 - val_root_mean_squared_error: 43.0187\n",
      "Epoch 40/100\n",
      "388/388 [==============================] - 0s 309us/sample - loss: 4068.6693 - root_mean_squared_error: 63.7861 - val_loss: 1588.2150 - val_root_mean_squared_error: 39.8524\n",
      "Epoch 41/100\n",
      "388/388 [==============================] - 0s 350us/sample - loss: 3547.3287 - root_mean_squared_error: 59.5595 - val_loss: 1908.6499 - val_root_mean_squared_error: 43.6881\n",
      "Epoch 42/100\n",
      "388/388 [==============================] - 0s 322us/sample - loss: 3412.4611 - root_mean_squared_error: 58.4163 - val_loss: 1620.7391 - val_root_mean_squared_error: 40.2584\n",
      "Epoch 43/100\n",
      "388/388 [==============================] - 0s 320us/sample - loss: 3006.1758 - root_mean_squared_error: 54.8286 - val_loss: 1710.9741 - val_root_mean_squared_error: 41.3639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "388/388 [==============================] - 0s 315us/sample - loss: 3837.3266 - root_mean_squared_error: 61.9462 - val_loss: 1753.0383 - val_root_mean_squared_error: 41.8693\n",
      "Epoch 45/100\n",
      "388/388 [==============================] - 0s 318us/sample - loss: 3242.2104 - root_mean_squared_error: 56.9404 - val_loss: 2061.7256 - val_root_mean_squared_error: 45.4062\n",
      "Epoch 46/100\n",
      "388/388 [==============================] - 0s 316us/sample - loss: 3853.5863 - root_mean_squared_error: 62.0773 - val_loss: 1519.1201 - val_root_mean_squared_error: 38.9759\n",
      "Epoch 47/100\n",
      "388/388 [==============================] - 0s 332us/sample - loss: 3141.5862 - root_mean_squared_error: 56.0499 - val_loss: 2144.1057 - val_root_mean_squared_error: 46.3045\n",
      "Epoch 48/100\n",
      "388/388 [==============================] - 0s 352us/sample - loss: 3757.7944 - root_mean_squared_error: 61.3008 - val_loss: 1673.9925 - val_root_mean_squared_error: 40.9145\n",
      "Epoch 49/100\n",
      "388/388 [==============================] - 0s 304us/sample - loss: 3068.6239 - root_mean_squared_error: 55.3952 - val_loss: 1701.9521 - val_root_mean_squared_error: 41.2547\n",
      "Epoch 50/100\n",
      "388/388 [==============================] - 0s 321us/sample - loss: 2973.3906 - root_mean_squared_error: 54.5288 - val_loss: 1823.5583 - val_root_mean_squared_error: 42.7031\n",
      "Epoch 51/100\n",
      "388/388 [==============================] - 0s 267us/sample - loss: 3143.3518 - root_mean_squared_error: 56.0656 - val_loss: 1832.3165 - val_root_mean_squared_error: 42.8056\n",
      "Epoch 52/100\n",
      "388/388 [==============================] - 0s 303us/sample - loss: 2885.1753 - root_mean_squared_error: 53.7138 - val_loss: 2113.9186 - val_root_mean_squared_error: 45.9774\n",
      "Epoch 53/100\n",
      "388/388 [==============================] - 0s 272us/sample - loss: 3118.0471 - root_mean_squared_error: 55.8395 - val_loss: 1194.4777 - val_root_mean_squared_error: 34.5612\n",
      "Epoch 54/100\n",
      "388/388 [==============================] - 0s 302us/sample - loss: 2699.0482 - root_mean_squared_error: 51.9524 - val_loss: 1713.1892 - val_root_mean_squared_error: 41.3907\n",
      "Epoch 55/100\n",
      "388/388 [==============================] - 0s 264us/sample - loss: 2305.0173 - root_mean_squared_error: 48.0106 - val_loss: 1215.1171 - val_root_mean_squared_error: 34.8585\n",
      "Epoch 56/100\n",
      "388/388 [==============================] - 0s 261us/sample - loss: 2571.3643 - root_mean_squared_error: 50.7086 - val_loss: 970.6132 - val_root_mean_squared_error: 31.1547\n",
      "Epoch 57/100\n",
      "388/388 [==============================] - 0s 296us/sample - loss: 2108.8446 - root_mean_squared_error: 45.9222 - val_loss: 1929.6074 - val_root_mean_squared_error: 43.9273\n",
      "Epoch 58/100\n",
      "388/388 [==============================] - 0s 264us/sample - loss: 1978.0244 - root_mean_squared_error: 44.4750 - val_loss: 926.9559 - val_root_mean_squared_error: 30.4460\n",
      "Epoch 59/100\n",
      "388/388 [==============================] - 0s 322us/sample - loss: 2200.1789 - root_mean_squared_error: 46.9061 - val_loss: 1451.7417 - val_root_mean_squared_error: 38.1017\n",
      "Epoch 60/100\n",
      "388/388 [==============================] - 0s 269us/sample - loss: 1979.2432 - root_mean_squared_error: 44.4887 - val_loss: 1288.1606 - val_root_mean_squared_error: 35.8910\n",
      "Epoch 61/100\n",
      "388/388 [==============================] - 0s 294us/sample - loss: 2512.1380 - root_mean_squared_error: 50.1212 - val_loss: 949.3270 - val_root_mean_squared_error: 30.8112\n",
      "Epoch 62/100\n",
      "388/388 [==============================] - 0s 280us/sample - loss: 2350.6845 - root_mean_squared_error: 48.4839 - val_loss: 1704.5628 - val_root_mean_squared_error: 41.2864\n",
      "Epoch 63/100\n",
      "388/388 [==============================] - 0s 300us/sample - loss: 2377.9937 - root_mean_squared_error: 48.7647 - val_loss: 1191.5592 - val_root_mean_squared_error: 34.5190\n",
      "Epoch 64/100\n",
      "388/388 [==============================] - 0s 266us/sample - loss: 2210.5157 - root_mean_squared_error: 47.0161 - val_loss: 1076.3276 - val_root_mean_squared_error: 32.8074\n",
      "Epoch 65/100\n",
      "388/388 [==============================] - 0s 281us/sample - loss: 2106.6368 - root_mean_squared_error: 45.8981 - val_loss: 1893.6916 - val_root_mean_squared_error: 43.5166\n",
      "Epoch 66/100\n",
      "388/388 [==============================] - 0s 299us/sample - loss: 2242.0087 - root_mean_squared_error: 47.3499 - val_loss: 931.7074 - val_root_mean_squared_error: 30.5239\n",
      "Epoch 67/100\n",
      "388/388 [==============================] - 0s 275us/sample - loss: 2525.5801 - root_mean_squared_error: 50.2551 - val_loss: 1673.3789 - val_root_mean_squared_error: 40.9070\n",
      "Epoch 68/100\n",
      "388/388 [==============================] - 0s 383us/sample - loss: 2177.6078 - root_mean_squared_error: 46.6648 - val_loss: 1198.8286 - val_root_mean_squared_error: 34.6241\n",
      "Epoch 69/100\n",
      "388/388 [==============================] - 0s 339us/sample - loss: 2100.0360 - root_mean_squared_error: 45.8261 - val_loss: 1306.4460 - val_root_mean_squared_error: 36.1448\n",
      "Epoch 70/100\n",
      "388/388 [==============================] - 0s 266us/sample - loss: 2206.0725 - root_mean_squared_error: 46.9688 - val_loss: 1312.3407 - val_root_mean_squared_error: 36.2262\n",
      "Epoch 71/100\n",
      "388/388 [==============================] - 0s 298us/sample - loss: 2096.9096 - root_mean_squared_error: 45.7920 - val_loss: 1076.3118 - val_root_mean_squared_error: 32.8072\n",
      "Epoch 72/100\n",
      "388/388 [==============================] - 0s 231us/sample - loss: 1984.7264 - root_mean_squared_error: 44.5503 - val_loss: 1447.6498 - val_root_mean_squared_error: 38.0480\n",
      "Epoch 73/100\n",
      "388/388 [==============================] - 0s 318us/sample - loss: 2273.1672 - root_mean_squared_error: 47.6777 - val_loss: 1145.8082 - val_root_mean_squared_error: 33.8498\n",
      "Epoch 74/100\n",
      "388/388 [==============================] - ETA: 0s - loss: 2122.6552 - root_mean_squared_error: 46.072 - 0s 336us/sample - loss: 2210.7544 - root_mean_squared_error: 47.0187 - val_loss: 1301.0773 - val_root_mean_squared_error: 36.0704\n",
      "Epoch 75/100\n",
      "388/388 [==============================] - 0s 331us/sample - loss: 2274.6730 - root_mean_squared_error: 47.6935 - val_loss: 1437.6950 - val_root_mean_squared_error: 37.9170\n",
      "Epoch 76/100\n",
      "388/388 [==============================] - 0s 307us/sample - loss: 2221.6413 - root_mean_squared_error: 47.1343 - val_loss: 1073.0330 - val_root_mean_squared_error: 32.7572\n",
      "Epoch 77/100\n",
      "388/388 [==============================] - 0s 265us/sample - loss: 2305.1714 - root_mean_squared_error: 48.0122 - val_loss: 1617.9309 - val_root_mean_squared_error: 40.2235\n",
      "Epoch 78/100\n",
      "388/388 [==============================] - 0s 317us/sample - loss: 2288.6979 - root_mean_squared_error: 47.8403 - val_loss: 1380.8675 - val_root_mean_squared_error: 37.1600\n",
      "Epoch 79/100\n",
      "388/388 [==============================] - 0s 371us/sample - loss: 2188.6354 - root_mean_squared_error: 46.7829 - val_loss: 1145.6793 - val_root_mean_squared_error: 33.8479\n",
      "Epoch 80/100\n",
      "388/388 [==============================] - 0s 272us/sample - loss: 2139.6472 - root_mean_squared_error: 46.2563 - val_loss: 1567.2050 - val_root_mean_squared_error: 39.5879\n",
      "Epoch 81/100\n",
      "388/388 [==============================] - 0s 319us/sample - loss: 2285.4062 - root_mean_squared_error: 47.8059 - val_loss: 1064.3770 - val_root_mean_squared_error: 32.6248\n",
      "Epoch 82/100\n",
      "388/388 [==============================] - 0s 325us/sample - loss: 1785.1824 - root_mean_squared_error: 42.2514 - val_loss: 1650.2093 - val_root_mean_squared_error: 40.6228\n",
      "Epoch 83/100\n",
      "388/388 [==============================] - 0s 321us/sample - loss: 2272.3236 - root_mean_squared_error: 47.6689 - val_loss: 1028.3345 - val_root_mean_squared_error: 32.0677\n",
      "Epoch 84/100\n",
      "388/388 [==============================] - 0s 300us/sample - loss: 2146.2128 - root_mean_squared_error: 46.3272 - val_loss: 1343.3428 - val_root_mean_squared_error: 36.6516\n",
      "Epoch 85/100\n",
      "388/388 [==============================] - 0s 252us/sample - loss: 1720.6314 - root_mean_squared_error: 41.4805 - val_loss: 1192.0176 - val_root_mean_squared_error: 34.5256\n",
      "Epoch 86/100\n",
      "388/388 [==============================] - 0s 280us/sample - loss: 1591.9968 - root_mean_squared_error: 39.8998 - val_loss: 1337.3620 - val_root_mean_squared_error: 36.5700\n",
      "Epoch 87/100\n",
      "388/388 [==============================] - 0s 270us/sample - loss: 1862.6842 - root_mean_squared_error: 43.1588 - val_loss: 1079.6905 - val_root_mean_squared_error: 32.8586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "388/388 [==============================] - 0s 335us/sample - loss: 1727.6728 - root_mean_squared_error: 41.5653 - val_loss: 1095.0192 - val_root_mean_squared_error: 33.0911\n",
      "Epoch 89/100\n",
      "388/388 [==============================] - 0s 344us/sample - loss: 1588.1874 - root_mean_squared_error: 39.8521 - val_loss: 1093.8571 - val_root_mean_squared_error: 33.0735\n",
      "Epoch 90/100\n",
      "388/388 [==============================] - 0s 326us/sample - loss: 1767.1913 - root_mean_squared_error: 42.0380 - val_loss: 1233.2551 - val_root_mean_squared_error: 35.1177\n",
      "Epoch 91/100\n",
      "388/388 [==============================] - 0s 260us/sample - loss: 2019.6410 - root_mean_squared_error: 44.9404 - val_loss: 1327.3201 - val_root_mean_squared_error: 36.4324\n",
      "Epoch 92/100\n",
      "388/388 [==============================] - 0s 288us/sample - loss: 2028.9154 - root_mean_squared_error: 45.0435 - val_loss: 988.7437 - val_root_mean_squared_error: 31.4443\n",
      "Epoch 93/100\n",
      "388/388 [==============================] - 0s 286us/sample - loss: 1787.8527 - root_mean_squared_error: 42.2830 - val_loss: 1154.4031 - val_root_mean_squared_error: 33.9765\n",
      "Epoch 94/100\n",
      "388/388 [==============================] - 0s 257us/sample - loss: 1785.9847 - root_mean_squared_error: 42.2609 - val_loss: 1168.4458 - val_root_mean_squared_error: 34.1825\n",
      "Epoch 95/100\n",
      "388/388 [==============================] - 0s 265us/sample - loss: 1531.2095 - root_mean_squared_error: 39.1307 - val_loss: 851.0332 - val_root_mean_squared_error: 29.1725\n",
      "Epoch 96/100\n",
      "388/388 [==============================] - 0s 291us/sample - loss: 1689.6942 - root_mean_squared_error: 41.1059 - val_loss: 1138.5678 - val_root_mean_squared_error: 33.7427\n",
      "Epoch 97/100\n",
      "388/388 [==============================] - 0s 345us/sample - loss: 1659.3246 - root_mean_squared_error: 40.7348 - val_loss: 949.2205 - val_root_mean_squared_error: 30.8094\n",
      "Epoch 98/100\n",
      "388/388 [==============================] - 0s 336us/sample - loss: 1630.9716 - root_mean_squared_error: 40.3853 - val_loss: 758.8272 - val_root_mean_squared_error: 27.5468\n",
      "Epoch 99/100\n",
      "388/388 [==============================] - 0s 352us/sample - loss: 1560.7121 - root_mean_squared_error: 39.5058 - val_loss: 1266.4128 - val_root_mean_squared_error: 35.5867\n",
      "Epoch 100/100\n",
      "388/388 [==============================] - 0s 243us/sample - loss: 1983.4803 - root_mean_squared_error: 44.5363 - val_loss: 1081.6779 - val_root_mean_squared_error: 32.8889\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model_100_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv('./history.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
